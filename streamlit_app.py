import streamlit as st
import numpy as np
import cv2
import json

# ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’æ ¼ç´ã™ã‚‹ãŸã‚ã®è¾æ›¸
debug_info = {}

# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ï¼ˆå¤‰æ›´ãªã—ï¼‰ ---

# ç”»åƒã‚’ãƒªã‚µã‚¤ã‚ºã—ã€ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ç¶­æŒ
def resize_image(image, max_width=800):
    (h, w) = image.shape[:2]
    if w > max_width:
        ratio = max_width / float(w)
        dim = (max_width, int(h * ratio))
        resized = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)
        return resized
    return image

# ãƒãƒ‹ãƒ¥ã‚¢ãƒ«åº§æ¨™å…¥åŠ›ç”¨ã®UIã‚’è¡¨ç¤º
def display_manual_input(image):
    st.subheader("æ‰‹å‹•åº§æ¨™å…¥åŠ›")
    st.warning("è‡ªå‹•è£œæ­£ã«å¤±æ•—ã—ã¾ã—ãŸã€‚åŸºæº–ã¨ãªã‚‹ç´™ã®4ã¤ã®è§’ã‚’ä»¥ä¸‹ã®é †åºã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    st.info("ç”»åƒã®å·¦ä¸Šã€å³ä¸Šã€å³ä¸‹ã€å·¦ä¸‹ã®é †ã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã§åº§æ¨™ã‚’ä¿æŒ
    if 'manual_coords' not in st.session_state:
        st.session_state.manual_coords = [None, None, None, None]

    cols = st.columns(4)
    labels = ["å·¦ä¸Š", "å³ä¸Š", "å³ä¸‹", "å·¦ä¸‹"]
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒåº§æ¨™ã‚’å…¥åŠ›ã™ã‚‹ãŸã‚ã®æ•°å€¤å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    for i, label in enumerate(labels):
        with cols[i]:
            # Xåº§æ¨™
            st.session_state.manual_coords[i] = st.number_input(
                f"{label} Xåº§æ¨™ (0-{image.shape[1]})",
                min_value=0,
                max_value=image.shape[1],
                value=st.session_state.manual_coords[i][0] if st.session_state.manual_coords[i] else 0,
                key=f'x_coord_{i}'
            )
            # Yåº§æ¨™
            st.session_state.manual_coords[i] = (
                st.session_state.manual_coords[i],
                st.number_input(
                    f"{label} Yåº§æ¨™ (0-{image.shape[0]})",
                    min_value=0,
                    max_value=image.shape[0],
                    value=st.session_state.manual_coords[i][1] if st.session_state.manual_coords[i] and isinstance(st.session_state.manual_coords[i], tuple) else 0,
                    key=f'y_coord_{i}'
                )
            )

    # 4ç‚¹å…¨ã¦å…¥åŠ›ã•ã‚ŒãŸã‹ãƒã‚§ãƒƒã‚¯
    if all(isinstance(coord, tuple) and len(coord) == 2 for coord in st.session_state.manual_coords):
        # 4ç‚¹ã‚’Numpyé…åˆ—ã«å¤‰æ›
        manual_points = np.array([
            st.session_state.manual_coords[0], st.session_state.manual_coords[1],
            st.session_state.manual_coords[2], st.session_state.manual_coords[3]
        ], dtype="float32")
        
        # è£œæ­£é–‹å§‹ãƒœã‚¿ãƒ³ã®è¡¨ç¤º
        if st.button("æ‰‹å‹•è£œæ­£ã‚’é–‹å§‹"):
            return manual_points
    
    return None

# ç”»åƒã®ãƒ‘ãƒ¼ã‚¹ãƒšã‚¯ãƒ†ã‚£ãƒ–å¤‰æ›ï¼ˆå¤‰æ›´ãªã—ï¼‰
def four_point_transform(image, pts, target_width, target_height):
    rect = np.array([
        [0, 0], [target_width - 1, 0],
        [target_width - 1, target_height - 1], [0, target_height - 1]
    ], dtype = "float32")
    
    M = cv2.getPerspectiveTransform(pts, rect)
    warped = cv2.warpPerspective(image, M, (target_width, target_height))
    return warped, M

# ãƒ‘ãƒ¼ã‚¹ãƒšã‚¯ãƒ†ã‚£ãƒ–è£œæ­£ã•ã‚ŒãŸç”»åƒã‹ã‚‰æœã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’æŠ½å‡ºï¼ˆå¤‰æ›´ãªã—ï¼‰
def find_clothing_bounding_box(warped_image):
    # HSVã«å¤‰æ›ã—ã€æœã®è‰²ç¯„å›²ã‚’æ¤œå‡º
    hsv = cv2.cvtColor(warped_image, cv2.COLOR_BGR2HSV)
    
    # ã“ã“ã§ã¯ã€é’è‰²ã®æœã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã®ä¸€èˆ¬çš„ãªç¯„å›²ã‚’ä½¿ç”¨ã—ã¾ã™
    lower_blue = np.array([90, 50, 50])
    upper_blue = np.array([130, 255, 255])
    
    # ãƒã‚¹ã‚¯ã‚’ä½œæˆ
    mask = cv2.inRange(hsv, lower_blue, upper_blue)
    
    # ãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼å¤‰æ›ã§ãƒã‚¤ã‚ºã‚’é™¤å»ã—ã€é ˜åŸŸã‚’çµåˆ
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)
    
    # è¼ªéƒ­ã‚’æ¤œå‡º
    contours, _ = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if not contours:
        return None, None
    
    # æœ€å¤§ã®è¼ªéƒ­ã‚’è¦‹ã¤ã‘ã‚‹ï¼ˆé€šå¸¸ã€ãã‚ŒãŒæœå…¨ä½“ï¼‰
    largest_contour = max(contours, key=cv2.contourArea)
    
    # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’å–å¾—
    x, y, w, h = cv2.boundingRect(largest_contour)
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã¨ã—ã¦ãƒã‚¹ã‚¯ã‚’è¿½åŠ 
    debug_info['binary_mask'] = mask
    
    return (x, y, w, h), largest_contour

# æ¸¬å®šãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå¤‰æ›´ãªã—ï¼‰
def measure_clothing(bounding_box, paper_size_mm, pixels_per_metric):
    if bounding_box is None:
        return None
    
    x, y, w, h = bounding_box
    
    # å®Ÿéš›ã®æœã®å¯¸æ³•ã‚’è¨ˆç®—
    # ç€ä¸ˆ (yè»¸æ–¹å‘)
    height_cm = h / pixels_per_metric 
    # èº«å¹… (xè»¸æ–¹å‘)
    width_cm = w / pixels_per_metric
    
    return height_cm, width_cm

# 4ã¤ã®è§’ã‚’è‡ªå‹•æ¤œå‡ºã™ã‚‹ï¼ˆä¿®æ­£ãªã—ï¼‰
def find_quadrilateral(image):
    # ç”»åƒã‚’ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›ã—ã€ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ–ãƒ©ãƒ¼ã‚’é©ç”¨
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    
    # ã‚¨ãƒƒã‚¸æ¤œå‡º
    # Cannyæ¤œå‡ºå™¨ã‚’ä½¿ç”¨ã™ã‚‹å‰ã«ã€OpenCVãŒæœ€ã‚‚æˆåŠŸã—ã‚„ã™ã„ã‚ˆã†ã«ç”»åƒã‚’èª¿æ•´ã™ã‚‹
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®Photoshopã§ã®èª¿æ•´ã«ã‚ˆã‚Šã€ã“ã®éƒ¨åˆ†ã®æ¤œå‡ºç²¾åº¦ãŒå¤§ããå·¦å³ã•ã‚Œã‚‹
    edged = cv2.Canny(blurred, 50, 200)

    # è¼ªéƒ­ã‚’è¦‹ã¤ã‘ã‚‹
    contours, _ = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # è¼ªéƒ­ã‚’é¢ç©ã§ã‚½ãƒ¼ãƒˆã—ã€æœ€ã‚‚å¤§ããªã‚‚ã®ã‚’é¸æŠ
    contours = sorted(contours, key = cv2.contourArea, reverse = True)
    
    # 4ã¤ã®é ‚ç‚¹ã‚’æŒã¤å››è§’å½¢ã‚’è¦‹ã¤ã‘ã‚‹
    for c in contours:
        # è¼ªéƒ­ã®å‘¨å›²é•·ã‚’è¨ˆç®—
        peri = cv2.arcLength(c, True)
        # è¼ªéƒ­ã‚’è¿‘ä¼¼ã—ã€é ‚ç‚¹æ•°ã‚’ç¢ºèª
        approx = cv2.approxPolyDP(c, 0.02 * peri, True)
        
        # 4ã¤ã®é ‚ç‚¹ãŒã‚ã‚Šã€é–‰ã˜ãŸå½¢çŠ¶ã§ã‚ã‚Œã°ã€ãã‚ŒãŒåŸºæº–ã®ç´™ã¨ä»®å®š
        if len(approx) == 4:
            # é ‚ç‚¹ã®é †åºã‚’ (å·¦ä¸Š, å³ä¸Š, å³ä¸‹, å·¦ä¸‹) ã«ä¸¦ã¹æ›¿ãˆã‚‹
            points = approx.reshape(4, 2)
            
            # é ‚ç‚¹ã‚’æ­£ã—ã„é †åºã«ä¸¦ã¹æ›¿ãˆã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
            def order_points(pts):
                # 4ç‚¹ã‚’åˆæœŸåŒ–
                rect = np.zeros((4, 2), dtype = "float32")

                # å·¦ä¸Š (æœ€å°ã®åˆè¨ˆ) ã¨å³ä¸‹ (æœ€å¤§ã®åˆè¨ˆ)
                s = pts.sum(axis = 1)
                rect[0] = pts[np.argmin(s)] # å·¦ä¸Š
                rect[2] = pts[np.argmax(s)] # å³ä¸‹

                # å³ä¸Š (æœ€å°ã®å·®) ã¨å·¦ä¸‹ (æœ€å¤§ã®å·®)
                diff = np.diff(pts, axis = 1)
                rect[1] = pts[np.argmin(diff)] # å³ä¸Š
                rect[3] = pts[np.argmax(diff)] # å·¦ä¸‹

                return rect
            
            return order_points(points)

    return None

# æ¡å¯¸ãƒ—ãƒ­ã‚»ã‚¹å…¨ä½“ã‚’åˆ¶å¾¡ã™ã‚‹é–¢æ•°
def process_measurement(image):
    
    # åŸºæº–ã¨ãªã‚‹ç´™ã®ã‚µã‚¤ã‚ºï¼ˆç¸¦51cmã€æ¨ª38cm - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚«ã‚¹ã‚¿ãƒ ã‚µã‚¤ã‚ºï¼‰
    PAPER_HEIGHT_CM = 51.0
    PAPER_WIDTH_CM = 38.0
    
    # OpenCVãŒå‡¦ç†ã—ã‚„ã™ã„ã‚ˆã†ã«ç”»åƒã‚’ãƒªã‚µã‚¤ã‚ºï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¯è¦‹ãˆãªã„ï¼‰
    processed_image = resize_image(image)

    # 1. åŸºæº–ã¨ãªã‚‹ç´™ã®4ã¤ã®è§’ã‚’æ¤œå‡º
    st.info("ã‚¹ãƒ†ãƒƒãƒ— 1/3: åŸºæº–ã¨ãªã‚‹ç´™ã®4ã¤ã®è§’ã‚’è‡ªå‹•æ¤œå‡ºä¸­...")
    
    # --- æ¤œå‡ºã«å¤±æ•—ã—ãŸå ´åˆã®å‡¦ç†ã‚’è¿½åŠ  ---
    quad = find_quadrilateral(processed_image)

    if quad is None:
        st.error("è£œæ­£ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚åŸºæº–ã¨ãªã‚‹ç´™ï¼ˆ4ã¤ã®è§’ã‚’æŒã¤ç‰©ä½“ï¼‰ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.warning("æ‰‹å‹•ã§åº§æ¨™ã‚’å…¥åŠ›ã™ã‚‹ã‹ã€ç”»åƒï¼ˆç‰¹ã«å¢ƒç•Œç·šï¼‰ã‚’ã•ã‚‰ã«æ˜ç¢ºã«ã—ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
        
        # æ‰‹å‹•å…¥åŠ›UIã‚’è¡¨ç¤ºã—ã€çµæœã‚’å–å¾—
        manual_points = display_manual_input(processed_image)

        if manual_points is None:
            return # æ‰‹å‹•å…¥åŠ›ãŒå®Œäº†ã—ã¦ã„ãªã„å ´åˆã¯çµ‚äº†

        quad = manual_points # æ‰‹å‹•å…¥åŠ›ã•ã‚ŒãŸåº§æ¨™ã‚’ä½¿ç”¨

    # 2. ãƒ‘ãƒ¼ã‚¹ãƒšã‚¯ãƒ†ã‚£ãƒ–å¤‰æ›ã‚’å®Ÿè¡Œ
    st.info("ã‚¹ãƒ†ãƒƒãƒ— 2/3: ãƒ‘ãƒ¼ã‚¹ãƒšã‚¯ãƒ†ã‚£ãƒ–è£œæ­£ã‚’å®Ÿè¡Œä¸­...")
    
    # è£œæ­£å¾Œã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚µã‚¤ã‚ºã‚’ãƒ”ã‚¯ã‚»ãƒ«ã§å®šç¾©ï¼ˆã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ç¶­æŒï¼‰
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®å¹…ã¨é«˜ã•ã‚’ç´™ã®æ¯”ç‡ã«åˆã‚ã›ã‚‹
    # æœã®æ¡å¯¸ã«ã¯ç¸¦é•·ã®æ¯”ç‡ã§ååˆ†ãªãŸã‚ã€ã“ã“ã§ã¯ç¸¦é•·ã«èª¿æ•´
    TARGET_WIDTH = 800
    TARGET_HEIGHT = int(TARGET_WIDTH * (PAPER_HEIGHT_CM / PAPER_WIDTH_CM))
    
    # è£œæ­£å¾Œã®ç”»åƒã‚’å–å¾—
    warped_image_bgr, M = four_point_transform(processed_image, quad, TARGET_WIDTH, TARGET_HEIGHT)

    # 3. æ¡å¯¸ã¨çµæœã®è¡¨ç¤º
    st.info("ã‚¹ãƒ†ãƒƒãƒ— 3/3: æœã®å¯¸æ³•ã‚’æ¸¬å®šä¸­...")
    
    # ãƒ”ã‚¯ã‚»ãƒ«ã‚ãŸã‚Šã®ã‚»ãƒ³ãƒãƒ¡ãƒ¼ãƒˆãƒ«æ•°ã‚’è¨ˆç®— (ä¾‹: 800px / 38cm)
    pixels_per_cm = TARGET_WIDTH / PAPER_WIDTH_CM
    
    # æœã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’è¦‹ã¤ã‘ã‚‹
    bounding_box, largest_contour = find_clothing_bounding_box(warped_image_bgr)
    
    # æ¸¬å®šçµæœã‚’å–å¾—
    measurement_results = measure_clothing(bounding_box, (PAPER_HEIGHT_CM, PAPER_WIDTH_CM), pixels_per_cm)

    # æ¸¬å®šçµæœã®è¡¨ç¤º
    st.success("æ¡å¯¸ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    
    if measurement_results:
        height_cm, width_cm = measurement_results
        
        st.subheader("ğŸ“ è¨ˆæ¸¬çµæœ (ã‚«ã‚¹ã‚¿ãƒ åŸºæº–)")
        st.markdown(f"**ç€ä¸ˆ (æ¨å®š):** {height_cm:.1f} cm")
        st.markdown(f"**èº«å¹… (æ¨å®š):** {width_cm:.1f} cm")
        
        st.info("è¨ˆæ¸¬ã¯æœã®å¤–æ  (ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹) ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚")

    else:
        st.error("æœã®æ¤œå‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚æœãŒèƒŒæ™¯ï¼ˆç´™ï¼‰ã¨åŒã˜è‰²ã§ã¯ãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    # --- ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆçµæœã®è¦–è¦šåŒ–ï¼‰---
    
    # è£œæ­£ã•ã‚ŒãŸç”»åƒï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    warped_image_display = warped_image_bgr.copy()
    
    # æœã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’æç”»
    if bounding_box:
        x, y, w, h = bounding_box
        # æœã®å¤–æ ã‚’èµ¤è‰²ã§è¡¨ç¤º
        cv2.rectangle(warped_image_display, (x, y), (x + w, y + h), (0, 0, 255), 5)
        
    st.subheader("ğŸ› ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
    st.image(warped_image_display, channels="BGR", caption="ãƒ‘ãƒ¼ã‚¹ãƒšã‚¯ãƒ†ã‚£ãƒ–è£œæ­£å¾Œã®ç”»åƒã¨æ¨å®šãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹")
    
    # è¼ªéƒ­ãƒã‚¹ã‚¯ã®è¡¨ç¤º
    if 'binary_mask' in debug_info:
        st.image(debug_info['binary_mask'], caption="é–¾å€¤å‡¦ç†å¾Œã®ç”»åƒï¼ˆæœãŒç™½ãè¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªï¼‰", use_column_width=True)
        st.markdown(f"Pixels Per Metric (1cmã‚ãŸã‚Š): {pixels_per_cm:.2f} pixels")
        
    st.markdown(f"â€»ã“ã®ã‚¢ãƒ—ãƒªã¯ã€ç¸¦{PAPER_HEIGHT_CM}cmã€æ¨ª{PAPER_WIDTH_CM}cmã®ç´™ã®æ—¢çŸ¥ã®å¯¸æ³•ã‚’åŸºæº–ã¨ã—ã¦ã„ã¾ã™ã€‚")


# --- Streamlit UIï¼ˆå¤‰æ›´ãªã—ï¼‰ ---

st.title("ğŸ‘• æœã®è‡ªå‹•æ¡å¯¸ã‚¢ãƒ—ãƒª (ã‚«ã‚¹ã‚¿ãƒ åŸºæº–)")
st.markdown(f"æœã‚’ç¸¦51cmã€æ¨ª38cmã®ç´™ã«ç½®ã„ã¦æ’®å½±ã—ãŸç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

uploaded_file = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã“ã“ã«ãƒ‰ãƒ©ãƒƒã‚°ã‚¢ãƒ³ãƒ‰ãƒ‰ãƒ­ãƒƒãƒ—ã—ã¦ãã ã•ã„", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
    image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
    
    st.image(image, channels="BGR", caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ")

    if st.button("æ¡å¯¸é–‹å§‹"):
        try:
            process_measurement(image)
        except Exception as e:
            st.error(f"è¨ˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„: {e}")
