import streamlit as st
import numpy as np
import cv2
import json

# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ï¼ˆå¤‰æ›´ãªã—ï¼‰ ---

# ç”»åƒã‚’ãƒªã‚µã‚¤ã‚ºã—ã€ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ç¶­æŒ
def resize_image(image, max_width=800):
    (h, w) = image.shape[:2]
    if w > max_width:
        ratio = max_width / float(w)
        dim = (max_width, int(h * ratio))
        resized = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)
        return resized
    return image

# ç”»åƒã®ãƒ‘ãƒ¼ã‚¹ãƒšã‚¯ãƒ†ã‚£ãƒ–å¤‰æ›
def four_point_transform(image, pts, target_width, target_height):
    rect = np.array([
        [0, 0], [target_width - 1, 0],
        [target_width - 1, target_height - 1], [0, target_height - 1]
    ], dtype = "float32")
    
    M = cv2.getPerspectiveTransform(pts, rect)
    warped = cv2.warpPerspective(image, M, (target_width, target_height))
    return warped, M

# æ¸¬å®šãƒ­ã‚¸ãƒƒã‚¯
def measure_clothing(measurement_points, target_width, target_height, paper_width_cm, paper_height_cm):
    # è£œæ­£å¾Œã®ç”»åƒã‚µã‚¤ã‚ºï¼ˆãƒ”ã‚¯ã‚»ãƒ«ï¼‰
    x_px = measurement_points[:, 0]
    y_px = measurement_points[:, 1]
    
    # ãƒ”ã‚¯ã‚»ãƒ«ã‚ãŸã‚Šã®ã‚»ãƒ³ãƒãƒ¡ãƒ¼ãƒˆãƒ«æ•°ã‚’è¨ˆç®—
    pixels_per_cm_x = target_width / paper_width_cm
    pixels_per_cm_y = target_height / paper_height_cm
    
    # ç€ä¸ˆ (Yè»¸ã®æœ€å¤§å€¤ã¨æœ€å°å€¤ã®å·®) - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡å®šã—ãŸç€ä¸ˆã®å§‹ã¾ã‚Š(0)ã¨çµ‚ã‚ã‚Š(1)
    height_px = abs(y_px[1] - y_px[0])
    
    # èº«å¹… (Xè»¸ã®æœ€å¤§å€¤ã¨æœ€å°å€¤ã®å·®) - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡å®šã—ãŸèº«å¹…ã®å§‹ã¾ã‚Š(2)ã¨çµ‚ã‚ã‚Š(3)
    width_px = abs(x_px[3] - x_px[2])
    
    # å®Ÿéš›ã®æœã®å¯¸æ³•ã‚’è¨ˆç®—
    height_cm = height_px / pixels_per_cm_y
    width_cm = width_px / pixels_per_cm_x
    
    return height_cm, width_cm, pixels_per_cm_x, pixels_per_cm_y

# --- Streamlit UIã¨çŠ¶æ…‹ç®¡ç† ---

# åŸºæº–ã¨ãªã‚‹ç´™ã®ã‚µã‚¤ã‚ºï¼ˆç¸¦51cmã€æ¨ª38cm - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚«ã‚¹ã‚¿ãƒ ã‚µã‚¤ã‚ºï¼‰
PAPER_HEIGHT_CM = 51.0
PAPER_WIDTH_CM = 38.0

# è£œæ­£å¾Œã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚µã‚¤ã‚ºã‚’ãƒ”ã‚¯ã‚»ãƒ«ã§å®šç¾©
TARGET_WIDTH = 800
TARGET_HEIGHT = int(TARGET_WIDTH * (PAPER_HEIGHT_CM / PAPER_WIDTH_CM))

def init_session_state():
    # ã‚¢ãƒ—ãƒªã®ã‚¹ãƒ†ãƒƒãƒ— (1: ç´™ã®è§’æŒ‡å®š, 2: æ¡å¯¸ç‚¹æŒ‡å®š, 3: çµæœè¡¨ç¤º)
    if 'step' not in st.session_state:
        st.session_state.step = 1
    # ç¾åœ¨ç·¨é›†ä¸­ã®ãƒã‚¤ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    if 'active_point_index' not in st.session_state:
        st.session_state.active_point_index = 0
    
    # ç”»åƒãƒ‡ãƒ¼ã‚¿
    if 'processed_image' not in st.session_state:
        st.session_state.processed_image = None
    if 'original_image' not in st.session_state:
        st.session_state.original_image = None
        
    # åº§æ¨™ãƒ‡ãƒ¼ã‚¿ [å·¦ä¸Š, å³ä¸Š, å³ä¸‹, å·¦ä¸‹]
    if 'paper_coords' not in st.session_state:
        st.session_state.paper_coords = [None] * 4 
    # æ¡å¯¸ãƒ‡ãƒ¼ã‚¿ [ç€ä¸ˆä¸Š, ç€ä¸ˆä¸‹, èº«å¹…å·¦, èº«å¹…å³]
    if 'measure_coords' not in st.session_state:
        st.session_state.measure_coords = [None] * 4 

# ãƒã‚¤ãƒ³ãƒˆã®å…¥åŠ›ã‚’å‡¦ç†ã—ã€æ¬¡ã®ãƒã‚¤ãƒ³ãƒˆã¸é€²ã‚ã‚‹
def handle_coordinate_input(coords_list_key, point_index, x_val, y_val, next_step_label):
    # ç¾åœ¨ã®ãƒã‚¤ãƒ³ãƒˆã‚’ä¿å­˜
    st.session_state[coords_list_key][point_index] = (x_val, y_val)
    
    # æ¬¡ã®ãƒã‚¤ãƒ³ãƒˆã¸é€²ã‚€ã€ã¾ãŸã¯æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸ç§»è¡Œ
    if point_index < len(st.session_state[coords_list_key]) - 1:
        st.session_state.active_point_index += 1
    else:
        st.session_state.active_point_index = 0
        st.session_state.step += 1
    
    st.experimental_rerun()

# åº§æ¨™å…¥åŠ›UIã®å…±é€šãƒ­ã‚¸ãƒƒã‚¯
def coordinate_input_ui(image, coords_list_key, labels, is_original_image):
    
    # ç”»åƒã®è¡¨ç¤ºï¼ˆåº§æ¨™ç¢ºèªç”¨ï¼‰
    st.image(image, channels="BGR", caption=f"ã€ç¾åœ¨ç·¨é›†ä¸­ã®ç”»åƒã€‘ ã‚µã‚¤ã‚º: {image.shape[1]} x {image.shape[0]}", use_column_width=True)

    # ç¾åœ¨ã®åº§æ¨™ãƒªã‚¹ãƒˆã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã€Noneã‚’(0, 0)ã«åˆæœŸåŒ–
    current_coords = [
        (0, 0) if coord is None else coord 
        for coord in st.session_state[coords_list_key]
    ]

    # --- 1. é¸æŠä¸­ã®ãƒã‚¤ãƒ³ãƒˆã‚’ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§è¡¨ç¤ºï¼ˆè¦–è¦šçš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼‰ ---
    
    # ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®é¸æŠè‚¢ï¼ˆNoneã‚’è¨±å®¹ã—ãªã„ãŸã‚ã€indexã§å‡¦ç†ï¼‰
    point_options = list(range(len(labels)))
    st.session_state.active_point_index = st.radio(
        "ğŸ’¡ ç¾åœ¨ã€è¨­å®šã—ãŸã„ãƒã‚¤ãƒ³ãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„:",
        point_options,
        index=st.session_state.active_point_index,
        format_func=lambda i: f"ã€{i+1}ã€‘ {labels[i]}",
        key=f'{coords_list_key}_active_point'
    )
    
    active_index = st.session_state.active_point_index
    active_label = labels[active_index]
    
    st.markdown("---")
    
    # --- 2. é¸æŠä¸­ã®ãƒã‚¤ãƒ³ãƒˆã®å…¥åŠ›æ¬„ã ã‘ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤º ---
    
    st.subheader(f"âœ¨ è¨­å®šä¸­: {active_label} ã®åº§æ¨™")
    
    # ç¾åœ¨ã®å€¤ã‚’å–å¾— (è¨­å®šæ¸ˆã¿ã®å€¤ã€ã¾ãŸã¯åˆæœŸå€¤)
    initial_x, initial_y = current_coords[active_index]
    
    col_x, col_y = st.columns(2)
    
    with col_x:
        x_val = st.number_input(
            f"Xåº§æ¨™ (0-{image.shape[1]}): {active_label}",
            min_value=0,
            max_value=image.shape[1],
            value=initial_x,
            key=f'{coords_list_key}_x_{active_index}'
        )
    with col_y:
        y_val = st.number_input(
            f"Yåº§æ¨™ (0-{image.shape[0]}): {active_label}",
            min_value=0,
            max_value=image.shape[0],
            value=initial_y,
            key=f'{coords_list_key}_y_{active_index}'
        )

    st.markdown("---")

    # --- 3. ç¢ºå®šãƒœã‚¿ãƒ³ï¼ˆã‚¯ãƒªãƒƒã‚¯ã§æ¬¡ã®ãƒã‚¤ãƒ³ãƒˆã¸ç§»å‹•ï¼‰ ---
    
    if st.button(f"âœ… {active_label} åº§æ¨™ã‚’ç¢ºå®šã—ã€æ¬¡ã®ãƒã‚¤ãƒ³ãƒˆã¸", key=f'{coords_list_key}_confirm_btn'):
        handle_coordinate_input(
            coords_list_key, active_index, x_val, y_val, active_label
        )
    
    # å…¨ã¦ã®ãƒã‚¤ãƒ³ãƒˆãŒè¨­å®šæ¸ˆã¿ã‹ç¢ºèª
    if all(coord is not None for coord in st.session_state[coords_list_key]):
        # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸é€²ã‚€ãŸã‚ã®ãƒœã‚¿ãƒ³
        st.success("å…¨ã¦ã®ãƒã‚¤ãƒ³ãƒˆãŒè¨­å®šã•ã‚Œã¾ã—ãŸï¼")
        if st.button("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸é€²ã‚€", key=f'{coords_list_key}_next_step_btn'):
            if is_original_image:
                # ã‚¹ãƒ†ãƒƒãƒ—1ã‹ã‚‰2ã¸ã®ç§»è¡Œï¼ˆè£œæ­£å‡¦ç†ãŒå¿…è¦ï¼‰
                st.session_state.step = 2 
            else:
                # ã‚¹ãƒ†ãƒƒãƒ—2ã‹ã‚‰3ã¸ã®ç§»è¡Œ
                st.session_state.step = 3
            st.experimental_rerun()
            
    # è¨­å®šæ¸ˆã¿ã®ãƒã‚¤ãƒ³ãƒˆã‚’ãƒãƒ¼ã‚¯ã—ãŸãƒ‡ãƒãƒƒã‚°ç”»åƒã‚’æº–å‚™
    display_debug_image(image, st.session_state[coords_list_key], labels)

def display_debug_image(image, coords_list, labels):
    if all(coord is not None for coord in coords_list):
        debug_image = image.copy()
        for i, (x, y) in enumerate(coords_list):
            x_int, y_int = int(x), int(y)
            # ç¾åœ¨ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒã‚¤ãƒ³ãƒˆã‚’é»„è‰²ã§å¼·èª¿
            color = (0, 255, 255) if i == st.session_state.active_point_index else (0, 0, 255) 
            cv2.circle(debug_image, (x_int, y_int), 15 if i == st.session_state.active_point_index else 5, color, -1)
            cv2.putText(debug_image, f"{i+1}:{labels[i]}", (x_int + 15, y_int), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
        st.subheader("ç¾åœ¨ã®åº§æ¨™ãƒãƒ¼ã‚¯ï¼ˆå…¥åŠ›ã—ãŸåº§æ¨™ã‚’ç¢ºèªï¼‰")
        st.image(debug_image, channels="BGR", caption="è¨­å®šã—ãŸãƒã‚¤ãƒ³ãƒˆã‚’èµ¤ã„ä¸¸ã§è¡¨ç¤º", use_column_width=True)


def main():
    init_session_state()

    st.title("ğŸ“ æœã®ã‚«ã‚¹ã‚¿ãƒ æ¡å¯¸ã‚¢ãƒ—ãƒª (ã‚¬ã‚¤ãƒ‰ä»˜ãæ‰‹å‹•å…¥åŠ›)")
    st.markdown("---")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼
    uploaded_file = st.file_uploader("ã‚¹ãƒ†ãƒƒãƒ— 0: ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        if st.session_state.original_image is None or st.session_state.uploaded_file_name != uploaded_file.name:
            # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå ´åˆã€çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
            st.session_state.step = 1
            st.session_state.active_point_index = 0
            st.session_state.uploaded_file_name = uploaded_file.name
            
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            original_image_bgr = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
            st.session_state.original_image = resize_image(original_image_bgr) # å‡¦ç†ç”¨ã«ãƒªã‚µã‚¤ã‚º

    if st.session_state.original_image is None:
        st.info("ç¸¦51cmã€æ¨ª38cmã®ç´™ã®ä¸Šã«æœã‚’ç½®ã„ã¦æ’®å½±ã—ãŸç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    # --- ã‚¹ãƒ†ãƒƒãƒ— 1: ç´™ã®è§’ã®æŒ‡å®šã¨ãƒ‘ãƒ¼ã‚¹ãƒšã‚¯ãƒ†ã‚£ãƒ–è£œæ­£ ---
    if st.session_state.step == 1:
        st.header("ã‚¹ãƒ†ãƒƒãƒ— 1/3: åŸºæº–ã¨ãªã‚‹ç´™ã®4ã¤ã®è§’ã‚’å…¥åŠ›")
        st.warning("ç´™ã®è§’ã®æ­£ç¢ºãª**X, Yåº§æ¨™**ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚åº§æ¨™ã¯Photoshopãªã©ã®ãƒ„ãƒ¼ãƒ«ã§ç¢ºèªã§ãã¾ã™ã€‚")
        st.info(f"ç´™ã®å¯¸æ³•: ç¸¦{PAPER_HEIGHT_CM}cm, æ¨ª{PAPER_WIDTH_CM}cm")
        
        # åº§æ¨™å…¥åŠ›UIã®å‘¼ã³å‡ºã—
        paper_labels = ["å·¦ä¸Š", "å³ä¸Š", "å³ä¸‹", "å·¦ä¸‹"]
        coordinate_input_ui(st.session_state.original_image, 'paper_coords', paper_labels, is_original_image=True)

    # --- ã‚¹ãƒ†ãƒƒãƒ— 2: ãƒ‘ãƒ¼ã‚¹ãƒšã‚¯ãƒ†ã‚£ãƒ–è£œæ­£ã¨æ¡å¯¸ç‚¹ã®æŒ‡å®š ---
    elif st.session_state.step == 2:
        st.header("ã‚¹ãƒ†ãƒƒãƒ— 2/3: æ¡å¯¸ç‚¹ã®å…¥åŠ› (è£œæ­£å¾Œç”»åƒ)")

        # ãƒ‘ãƒ¼ã‚¹ãƒšã‚¯ãƒ†ã‚£ãƒ–è£œæ­£ã‚’å®Ÿè¡Œ
        try:
            paper_points = np.array(st.session_state.paper_coords, dtype="float32")
            warped_image_bgr, _ = four_point_transform(
                st.session_state.original_image, paper_points, TARGET_WIDTH, TARGET_HEIGHT
            )
            st.session_state.processed_image = warped_image_bgr
            st.success("ãƒ‘ãƒ¼ã‚¹ãƒšã‚¯ãƒ†ã‚£ãƒ–è£œæ­£ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ä»¥ä¸‹ã®ç”»åƒãŒè£œæ­£å¾Œã®ç”»åƒã§ã™ã€‚")
        except Exception as e:
            st.error(f"ãƒ‘ãƒ¼ã‚¹ãƒšã‚¯ãƒ†ã‚£ãƒ–è£œæ­£ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¹ãƒ†ãƒƒãƒ—1ã®åº§æ¨™ã‚’å†ç¢ºèªã—ã¦ãã ã•ã„: {e}")
            if st.button("â† ã‚¹ãƒ†ãƒƒãƒ—1ã«æˆ»ã‚‹", key="back_to_step1_from_2"):
                st.session_state.step = 1
                st.experimental_rerun()
            return

        # åº§æ¨™å…¥åŠ›UIã®å‘¼ã³å‡ºã—
        measure_labels = ["ç€ä¸ˆ (ä¸Šç«¯)", "ç€ä¸ˆ (ä¸‹ç«¯)", "èº«å¹… (å·¦ç«¯)", "èº«å¹… (å³ç«¯)"]
        coordinate_input_ui(st.session_state.processed_image, 'measure_coords', measure_labels, is_original_image=False)
        
        # æˆ»ã‚‹ãƒœã‚¿ãƒ³
        if st.button("â† ç´™ã®è§’ã®æŒ‡å®šã«æˆ»ã‚‹", key="back_to_step1_alt"):
            st.session_state.step = 1
            st.experimental_rerun()


    # --- ã‚¹ãƒ†ãƒƒãƒ— 3: çµæœã®è¡¨ç¤º ---
    elif st.session_state.step == 3:
        st.header("ã‚¹ãƒ†ãƒƒãƒ— 3/3: æ¡å¯¸çµæœ")
        
        measure_points = np.array(st.session_state.measure_coords, dtype="float32")
        
        try:
            height_cm, width_cm, pixels_per_cm_x, pixels_per_cm_y = measure_clothing(
                measure_points, TARGET_WIDTH, TARGET_HEIGHT, PAPER_WIDTH_CM, PAPER_HEIGHT_CM
            )

            st.success("æ¡å¯¸ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            
            st.subheader("ğŸ“ è¨ˆæ¸¬çµæœ")
            st.markdown(f"**ç€ä¸ˆ (æ¨å®š):** **{height_cm:.1f} cm**")
            st.markdown(f"**èº«å¹… (æ¨å®š):** **{width_cm:.1f} cm**")
            
            st.info("çµæœã¯ã€ã‚«ã‚¹ã‚¿ãƒ åŸºæº–ï¼ˆç¸¦51cmã€æ¨ª38cmï¼‰ã¨ã€æ‰‹å‹•ã§æŒ‡å®šã—ãŸ4ç‚¹ã«åŸºã¥ã„ã¦è¨ˆç®—ã•ã‚Œã¦ã„ã¾ã™ã€‚")
            
            # --- çµæœã®è¦–è¦šåŒ– ---
            warped_image_display = st.session_state.processed_image.copy()
            
            # è¨ˆæ¸¬ç‚¹ã‚’æç”»: [ç€ä¸ˆä¸Š(é’), ç€ä¸ˆä¸‹(é’), èº«å¹…å·¦(ç·‘), èº«å¹…å³(ç·‘)]
            colors = [(255, 0, 0), (255, 0, 0), (0, 255, 0), (0, 255, 0)] # é’, é’, ç·‘, ç·‘
            labels_draw = ["ç€ä¸ˆä¸Š", "ç€ä¸ˆä¸‹", "èº«å¹…å·¦", "èº«å¹…å³"]

            for i, (x, y) in enumerate(st.session_state.measure_coords):
                x_int, y_int = int(x), int(y)
                cv2.circle(warped_image_display, (x_int, y_int), 10, colors[i], -1)
                cv2.putText(warped_image_display, labels_draw[i], (x_int + 15, y_int), cv2.FONT_HERSHEY_SIMPLEX, 0.7, colors[i], 2)

            # ç€ä¸ˆã®ç·š
            cv2.line(warped_image_display, 
                     (int(st.session_state.measure_coords[0][0]), int(st.session_state.measure_coords[0][1])), 
                     (int(st.session_state.measure_coords[1][0]), int(st.session_state.measure_coords[1][1])), 
                     (255, 0, 0), 3) # é’ç·š
            
            # èº«å¹…ã®ç·š
            cv2.line(warped_image_display, 
                     (int(st.session_state.measure_coords[2][0]), int(st.session_state.measure_coords[2][1])), 
                     (int(st.session_state.measure_coords[3][0]), int(st.session_state.measure_coords[3][1])), 
                     (0, 255, 0), 3) # ç·‘ç·š


            st.subheader("ğŸ› è¨ˆæ¸¬ç‚¹ã¨çµæœã®ç¢ºèª")
            st.image(warped_image_display, channels="BGR", caption="è¨ˆæ¸¬ç‚¹ã‚’æç”»ã—ãŸè£œæ­£å¾Œã®ç”»åƒ", use_column_width=True)
            
            st.markdown(f"**è©³ç´°ã‚¹ã‚±ãƒ¼ãƒ«æƒ…å ±:**")
            st.markdown(f"ãƒ»æ¨ªæ–¹å‘ (1cmã‚ãŸã‚Š): {pixels_per_cm_x:.2f} pixels")
            st.markdown(f"ãƒ»ç¸¦æ–¹å‘ (1cmã‚ãŸã‚Š): {pixels_per_cm_y:.2f} pixels")


        except Exception as e:
            st.error(f"è¨ˆæ¸¬ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¹ãƒ†ãƒƒãƒ—2ã®åº§æ¨™ã‚’å†ç¢ºèªã—ã¦ãã ã•ã„ã€‚: {e}")
            st.exception(e)
            
        # æˆ»ã‚‹ãƒœã‚¿ãƒ³
        if st.button("â† ã‚¹ãƒ†ãƒƒãƒ—2ã«æˆ»ã£ã¦å†èª¿æ•´ã™ã‚‹", key="back_to_step2_final"):
            st.session_state.step = 2
            st.experimental_rerun()

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ
if __name__ == '__main__':
    main()
