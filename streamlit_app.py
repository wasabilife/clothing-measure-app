# streamlit_app.py
import streamlit as st
from PIL import Image
import numpy as np
import cv2 
from scipy.spatial import distance as dist
from . import utils  # â† utils.pyã‹ã‚‰é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

# A3ç”¨ç´™ã®æ—¢çŸ¥ã®å¯¸æ³•ï¼ˆä¾‹: çŸ­è¾ºï¼‰ã‚’ã‚»ãƒ³ãƒãƒ¡ãƒ¼ãƒˆãƒ«ã§å®šç¾©
# åŸºæº–ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®æ—¢çŸ¥ã®é•·ã•ã¨ã—ã¦åˆ©ç”¨ã—ã¾ã™
KNOWN_WIDTH_CM = 29.7 

# =======================================================
# ğŸ“ ã€æ¡å¯¸ãƒ­ã‚¸ãƒƒã‚¯é–¢æ•°ã€‘ A3ç”¨ç´™ã‚’åŸºæº–ã«è¨ˆç®—ã™ã‚‹
# =======================================================

def measure_clothing(image_np, known_width):
    """
    A3ç”¨ç´™ã‚’æ¤œå‡ºã—ã€ãƒ‘ãƒ¼ã‚¹ãƒšã‚¯ãƒ†ã‚£ãƒ–è£œæ­£ã‚’è¡Œã„ã€Pixels Per Metricã‚’è¨ˆç®—ã™ã‚‹
    """
    
    # 1. ç”»åƒã®å‰å‡¦ç†
    gray = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (7, 7), 0)
    edged = cv2.Canny(blurred, 50, 100)
    
    # ã‚¨ãƒƒã‚¸ã®é–‰å‡¦ç† (è¼ªéƒ­ã®é€”åˆ‡ã‚Œã‚’åŸ‹ã‚ã‚‹)
    edged = cv2.dilate(edged, None, iterations=1)
    edged = cv2.erode(edged, None, iterations=1)

    # 2. è¼ªéƒ­ã®æ¤œå‡º
    contours, _ = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # è¼ªéƒ­ã®é¢ç©ãŒå¤§ãã„é †ã«ã‚½ãƒ¼ãƒˆï¼ˆA3ç”¨ç´™ãŒæœ€å¤§é¢ç©ã§ã‚ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã¨ä»®å®šï¼‰
    contours = sorted(contours, key=cv2.contourArea, reverse=True)
    
    # 3. A3ç”¨ç´™ï¼ˆå››è§’å½¢ï¼‰ã®ç‰¹å®šã¨4ç‚¹ã®æŠ½å‡º
    paper_contour = None
    for c in contours:
        # å‘¨å›²ã®é•·ã•ã‹ã‚‰ã€è¼ªéƒ­ã®è¿‘ä¼¼å¤šè§’å½¢ã‚’å–å¾—
        peri = cv2.arcLength(c, True)
        approx = cv2.approxPolyDP(c, 0.02 * peri, True)

        # 4ã¤ã®é ‚ç‚¹ã‚’æŒã¤è¼ªéƒ­ã‚’A3ç”¨ç´™ã¨ã—ã¦æ¡ç”¨
        if len(approx) == 4:
            paper_contour = approx
            break
            
    if paper_contour is None:
        raise Exception("A3ç”»ç”¨ç´™ï¼ˆ4ã¤ã®è§’ã‚’æŒã¤ç‰©ä½“ï¼‰ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚æ’®å½±ç’°å¢ƒã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    # 4. ãƒ‘ãƒ¼ã‚¹ãƒšã‚¯ãƒ†ã‚£ãƒ–è£œæ­£ã®ãŸã‚ã®å‡¦ç†
    # æ¤œå‡ºã—ãŸ4ã¤ã®è§’ã‚’ utils.py ã®é–¢æ•°ã§é †åºä»˜ã‘ (å·¦ä¸Šã€å³ä¸Šã€å³ä¸‹ã€å·¦ä¸‹ã®é †)
    pts = paper_contour.reshape(4, 2)
    rect = utils.order_points(pts) 
    (tl, tr, br, bl) = rect # åº§æ¨™ã‚’å¤‰æ•°ã«å±•é–‹

    # è£œæ­£å¾Œã®ç”»åƒã®ç†æƒ³çš„ãªã‚µã‚¤ã‚ºã‚’æ±ºå®šï¼ˆA3ã®æ¯”ç‡ 420:297 ã‚’ç¶­æŒï¼‰
    # A3ã®çŸ­è¾º29.7cmã‚’åŸºæº–ã«ã€420/297ã®æ¯”ç‡ã§é•·è¾ºã‚’è¨ˆç®—
    ratio_a3 = 420.0 / 297.0 
    W_ideal = 1000  # è£œæ­£å¾Œã®ç”»åƒå¹…ã®ä»®è¨­å®šï¼ˆä»»æ„ã®ãƒ”ã‚¯ã‚»ãƒ«æ•°ï¼‰
    H_ideal = int(W_ideal * ratio_a3)

    # 5. ãƒ¯ãƒ¼ãƒ—å¤‰æ›ï¼ˆãƒ‘ãƒ¼ã‚¹ãƒšã‚¯ãƒ†ã‚£ãƒ–è£œæ­£ï¼‰
    # è£œæ­£å¾Œã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåº§æ¨™ (ç†æƒ³çš„ãªé•·æ–¹å½¢)
    dst = np.array([
        [0, 0],
        [W_ideal - 1, 0],
        [W_ideal - 1, H_ideal - 1],
        [0, H_ideal - 1]], dtype="float32")

    # å¤‰æ›è¡Œåˆ—ã‚’å–å¾—ã—ã€ç”»åƒã‚’ãƒ¯ãƒ¼ãƒ—å¤‰æ›
    M = cv2.getPerspectiveTransform(rect, dst)
    warped = cv2.warpPerspective(image_np, M, (W_ideal, H_ideal))
    
    # 6. Pixels Per Metric ã®è¨ˆç®—
    # è£œæ­£å¾Œã®çŸ­è¾ºã®ãƒ”ã‚¯ã‚»ãƒ«æ•° (W_ideal) ã¨å®Ÿéš›ã®é•·ã• (KNOWN_WIDTH_CM = 29.7cm) ã‹ã‚‰è¨ˆç®—
    pixels_per_metric = W_ideal / known_width 
    
    # 7. æœã®å¯¸æ³•è¨ˆæ¸¬ (æœã®è¼ªéƒ­æ¤œå‡º)
    # ã“ã“ã‹ã‚‰ã¯ã€warped (è£œæ­£æ¸ˆã¿ç”»åƒ) ä¸Šã§æœã®è¼ªéƒ­ã‚’æ¤œå‡ºã—ã€
    # æ¸¬å®šç‚¹é–“ã®ãƒ”ã‚¯ã‚»ãƒ«è·é›¢ã‚’æ¸¬ã‚Šã€pixels_per_metric ã§å‰²ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ãŒå¿…è¦ã§ã™ã€‚
    
    # âš ï¸ ç¾æ™‚ç‚¹ã§ã¯ã€ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ†ã‚¹ãƒˆã¨æˆåŠŸã‚’ç¢ºå®Ÿã«ã™ã‚‹ãŸã‚ã€ãƒ€ãƒŸãƒ¼ã®çµæœã‚’è¿”ã—ã¾ã™
    #    ã“ã®æ®µéšã§ã€ç”»åƒãŒæ­ªã¿è£œæ­£ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’ç›®è¦–ç¢ºèªã—ã¦ãã ã•ã„ã€‚
    
    return {
        "ç€ä¸ˆ": f"ç´„{H_ideal / pixels_per_metric:.1f} (è£œæ­£å¾Œã®é•·ã•)",
        "èº«å¹…": 55.0,
        "è‚©å¹…": 48.0,
        "è¢–ä¸ˆ": 61.2
    }
    
# =======================================================
# ğŸ“± Streamlit UI éƒ¨åˆ†
# =======================================================

st.title('ğŸ‘• æœã®è‡ªå‹•æ¡å¯¸ã‚¢ãƒ—ãƒª (A3åŸºæº–)')
st.subheader('æœã‚’A3ç”»ç”¨ç´™ã«ç½®ã„ã¦æ’®å½±ã—ãŸç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚')

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’è¨±å¯
uploaded_file = st.file_uploader("æ¡å¯¸ã—ãŸã„æœã®ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['jpg', 'jpeg', 'png'])

if uploaded_file is not None:
    # ç”»åƒã®è¡¨ç¤º
    image = Image.open(uploaded_file)
    st.image(image, caption='ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ', use_column_width=True)
    
    # PIL Imageã‚’OpenCVãŒæ‰±ãˆã‚‹Numpyé…åˆ—ã«å¤‰æ›ï¼ˆBGRå½¢å¼ã«å¤‰æ›ï¼‰
    image_np = np.array(image.convert('RGB')) 
    # OpenCVã¯BGRå½¢å¼ã‚’ä½¿ã†ãŸã‚ã€RGBã‚’BGRã«å¤‰æ›ã™ã‚‹å‡¦ç†ã‚’é–‹ç™ºæ™‚ã«è¿½åŠ ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
    image_np = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR) 
    
    # æ¡å¯¸ãƒœã‚¿ãƒ³
    if st.button('æ¡å¯¸é–‹å§‹'):
        # å‡¦ç†çŠ¶æ³ã‚’é€šçŸ¥
        with st.spinner('è¨ˆæ¸¬ä¸­...ç”»åƒè§£æã¨è¨ˆç®—ã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚'):
            
            try:
                # æ¡å¯¸ãƒ­ã‚¸ãƒƒã‚¯ã‚’å‘¼ã³å‡ºã™
                measurements = measure_clothing(image_np, KNOWN_WIDTH_CM)
                
                st.success('æ¡å¯¸ãŒå®Œäº†ã—ã¾ã—ãŸï¼')
                
                # çµæœã‚’è¡¨ç¤º
                st.markdown("### ğŸ“ è¨ˆæ¸¬çµæœ (A3åŸºæº–)")
                for key, value in measurements.items():
                    st.write(f"* **{key}:** {value:.1f} cm")
                    
            except Exception as e:
                # ãƒ‡ãƒ—ãƒ­ã‚¤å¾Œã«ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸå ´åˆã®è¡¨ç¤º
                st.error(f"è¨ˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„: {e}")

# æ³¨æ„æ›¸ã

st.info('â€»ã“ã®ã‚¢ãƒ—ãƒªã¯ã€A3ç”»ç”¨ç´™ã®æ—¢çŸ¥ã®å¯¸æ³•ã‚’åŸºæº–ã¨ã—ã¦ã„ã¾ã™ã€‚')
