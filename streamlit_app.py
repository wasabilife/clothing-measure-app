import streamlit as st
import numpy as np
import cv2
import json

# ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’æ ¼ç´ã™ã‚‹ãŸã‚ã®è¾æ›¸
debug_info = {}

# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ---

# ç”»åƒã‚’ãƒªã‚µã‚¤ã‚ºã—ã€ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ç¶­æŒ
def resize_image(image, max_width=800):
    (h, w) = image.shape[:2]
    if w > max_width:
        ratio = max_width / float(w)
        dim = (max_width, int(h * ratio))
        resized = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)
        return resized
    return image

# ç”»åƒã®ãƒ‘ãƒ¼ã‚¹ãƒšã‚¯ãƒ†ã‚£ãƒ–å¤‰æ›
def four_point_transform(image, pts, target_width, target_height):
    rect = np.array([
        [0, 0], [target_width - 1, 0],
        [target_width - 1, target_height - 1], [0, target_height - 1]
    ], dtype = "float32")
    
    M = cv2.getPerspectiveTransform(pts, rect)
    warped = cv2.warpPerspective(image, M, (target_width, target_height))
    return warped, M

# æ¸¬å®šãƒ­ã‚¸ãƒƒã‚¯
def measure_clothing(measurement_points, target_width, target_height, paper_width_cm, paper_height_cm):
    
    # è£œæ­£å¾Œã®ç”»åƒã‚µã‚¤ã‚ºï¼ˆãƒ”ã‚¯ã‚»ãƒ«ï¼‰
    x_px = measurement_points[:, 0]
    y_px = measurement_points[:, 1]
    
    # ãƒ”ã‚¯ã‚»ãƒ«ã‚ãŸã‚Šã®ã‚»ãƒ³ãƒãƒ¡ãƒ¼ãƒˆãƒ«æ•°ã‚’è¨ˆç®—
    pixels_per_cm_x = target_width / paper_width_cm
    pixels_per_cm_y = target_height / paper_height_cm
    
    # ç€ä¸ˆ (Yè»¸ã®æœ€å¤§å€¤ã¨æœ€å°å€¤ã®å·®)
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡å®šã—ãŸç€ä¸ˆã®å§‹ã¾ã‚Š(0)ã¨çµ‚ã‚ã‚Š(1)
    height_px = abs(y_px[1] - y_px[0])
    
    # èº«å¹… (Xè»¸ã®æœ€å¤§å€¤ã¨æœ€å°å€¤ã®å·®)
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡å®šã—ãŸèº«å¹…ã®å§‹ã¾ã‚Š(2)ã¨çµ‚ã‚ã‚Š(3)
    width_px = abs(x_px[3] - x_px[2])
    
    # å®Ÿéš›ã®æœã®å¯¸æ³•ã‚’è¨ˆç®—
    # ç¸¦æ–¹å‘ã®è¨ˆæ¸¬ã«ã¯yã®ã‚¹ã‚±ãƒ¼ãƒ«ã€æ¨ªæ–¹å‘ã®è¨ˆæ¸¬ã«ã¯xã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚’ä½¿ç”¨
    height_cm = height_px / pixels_per_cm_y
    width_cm = width_px / pixels_per_cm_x
    
    return height_cm, width_cm, pixels_per_cm_x, pixels_per_cm_y

# --- Streamlit UIã¨çŠ¶æ…‹ç®¡ç† ---

# åŸºæº–ã¨ãªã‚‹ç´™ã®ã‚µã‚¤ã‚ºï¼ˆç¸¦51cmã€æ¨ª38cm - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚«ã‚¹ã‚¿ãƒ ã‚µã‚¤ã‚ºï¼‰
PAPER_HEIGHT_CM = 51.0
PAPER_WIDTH_CM = 38.0

# è£œæ­£å¾Œã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚µã‚¤ã‚ºã‚’ãƒ”ã‚¯ã‚»ãƒ«ã§å®šç¾©ï¼ˆã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ç¶­æŒï¼‰
TARGET_WIDTH = 800
TARGET_HEIGHT = int(TARGET_WIDTH * (PAPER_HEIGHT_CM / PAPER_WIDTH_CM))

def init_session_state():
    if 'step' not in st.session_state:
        st.session_state.step = 1
    if 'processed_image' not in st.session_state:
        st.session_state.processed_image = None
    if 'original_image' not in st.session_state:
        st.session_state.original_image = None
    if 'paper_coords' not in st.session_state:
        st.session_state.paper_coords = [None] * 4 # [å·¦ä¸Š, å³ä¸Š, å³ä¸‹, å·¦ä¸‹]
    if 'measure_coords' not in st.session_state:
        st.session_state.measure_coords = [None] * 4 # [ç€ä¸ˆä¸Š, ç€ä¸ˆä¸‹, èº«å¹…å·¦, èº«å¹…å³]

def main():
    init_session_state()

    st.title("ğŸ“ æœã®ã‚«ã‚¹ã‚¿ãƒ æ¡å¯¸ã‚¢ãƒ—ãƒª")
    st.markdown("---")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼
    uploaded_file = st.file_uploader("ã‚¹ãƒ†ãƒƒãƒ— 0: ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        if st.session_state.original_image is None or st.session_state.uploaded_file_name != uploaded_file.name:
            # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå ´åˆã€çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
            st.session_state.step = 1
            st.session_state.uploaded_file_name = uploaded_file.name
            
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            original_image_bgr = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
            st.session_state.original_image = resize_image(original_image_bgr) # å‡¦ç†ç”¨ã«ãƒªã‚µã‚¤ã‚º

    if st.session_state.original_image is None:
        st.info("ç¸¦51cmã€æ¨ª38cmã®ç´™ã®ä¸Šã«æœã‚’ç½®ã„ã¦æ’®å½±ã—ãŸç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    # --- ã‚¹ãƒ†ãƒƒãƒ— 1: ç´™ã®è§’ã®æŒ‡å®šã¨ãƒ‘ãƒ¼ã‚¹ãƒšã‚¯ãƒ†ã‚£ãƒ–è£œæ­£ ---
    if st.session_state.step == 1:
        st.header("ã‚¹ãƒ†ãƒƒãƒ— 1: åŸºæº–ã¨ãªã‚‹ç´™ã®4ã¤ã®è§’ã‚’å…¥åŠ›")
        st.warning("ç´™ã®è§’ã®æ­£ç¢ºãª**X, Yåº§æ¨™**ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚åº§æ¨™ã¯Photoshopãªã©ã®ãƒ„ãƒ¼ãƒ«ã§ç¢ºèªã§ãã¾ã™ã€‚")
        st.info(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒã‚µã‚¤ã‚º: {st.session_state.original_image.shape[1]} x {st.session_state.original_image.shape[0]} (ãƒªã‚µã‚¤ã‚ºå¾Œ)")
        
        st.image(st.session_state.original_image, channels="BGR", caption="å…ƒã®ç”»åƒï¼ˆã“ã®ç”»åƒã‚’å‚è€ƒã«åº§æ¨™ã‚’å…¥åŠ›ï¼‰", use_column_width=True)

        labels = ["å·¦ä¸Š", "å³ä¸Š", "å³ä¸‹", "å·¦ä¸‹"]
        col_x, col_y = st.columns(2)
        
        for i, label in enumerate(labels):
            with col_x if i % 2 == 0 else col_y:
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒåº§æ¨™ã‚’å…¥åŠ›ã™ã‚‹ãŸã‚ã®æ•°å€¤å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
                st.subheader(f"{label}ã®åº§æ¨™")
                x_val = st.number_input(
                    f"{label} Xåº§æ¨™",
                    min_value=0,
                    max_value=st.session_state.original_image.shape[1],
                    value=st.session_state.paper_coords[i][0] if st.session_state.paper_coords[i] else 0,
                    key=f'paper_x_{i}'
                )
                y_val = st.number_input(
                    f"{label} Yåº§æ¨™",
                    min_value=0,
                    max_value=st.session_state.original_image.shape[0],
                    value=st.session_state.paper_coords[i][1] if st.session_state.paper_coords[i] else 0,
                    key=f'paper_y_{i}'
                )
                st.session_state.paper_coords[i] = (x_val, y_val)


        if st.button("ç”»åƒã‚’è£œæ­£ã—ã€ã‚¹ãƒ†ãƒƒãƒ—2ã¸é€²ã‚€", key="go_to_step2"):
            try:
                # 4ç‚¹ã‚’Numpyé…åˆ—ã«å¤‰æ›
                paper_points = np.array(st.session_state.paper_coords, dtype="float32")
                
                # è£œæ­£ã‚’å®Ÿè¡Œ
                warped_image_bgr, _ = four_point_transform(
                    st.session_state.original_image, paper_points, TARGET_WIDTH, TARGET_HEIGHT
                )
                
                st.session_state.processed_image = warped_image_bgr
                st.session_state.step = 2
                st.experimental_rerun() # ã‚¹ãƒ†ãƒƒãƒ—2ã¸ç§»è¡Œ

            except Exception as e:
                st.error(f"ãƒ‘ãƒ¼ã‚¹ãƒšã‚¯ãƒ†ã‚£ãƒ–è£œæ­£ã«å¤±æ•—ã—ã¾ã—ãŸã€‚åº§æ¨™å…¥åŠ›ãŒé–“é•ã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™: {e}")
                st.exception(e)

    # --- ã‚¹ãƒ†ãƒƒãƒ— 2: ç€ä¸ˆãƒ»èº«å¹…ã®æ¡å¯¸ç‚¹ã‚’æŒ‡å®š ---
    elif st.session_state.step == 2:
        st.header("ã‚¹ãƒ†ãƒƒãƒ— 2: ç€ä¸ˆãƒ»èº«å¹…ã®è¨ˆæ¸¬ç‚¹ã‚’å…¥åŠ›")
        st.info("è£œæ­£å¾Œã®ç”»åƒã‚’è¦‹ãªãŒã‚‰ã€æœã®æ¡å¯¸ã«å¿…è¦ãª4ç‚¹ã®æ­£ç¢ºãªX, Yåº§æ¨™ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        st.warning(f"è£œæ­£å¾Œã®ç”»åƒã‚µã‚¤ã‚º: {TARGET_WIDTH} x {TARGET_HEIGHT}ã€‚åº§æ¨™ã¯ã“ã®ç¯„å›²å†…ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        
        # è£œæ­£å¾Œã®ç”»åƒã‚’è¡¨ç¤º
        st.image(st.session_state.processed_image, channels="BGR", 
                 caption="è£œæ­£å¾Œã®ç”»åƒï¼ˆã“ã®ç”»åƒã‚’å‚è€ƒã«åº§æ¨™ã‚’å…¥åŠ›ï¼‰", use_column_width=True)

        labels = ["ç€ä¸ˆ (ä¸Šç«¯)", "ç€ä¸ˆ (ä¸‹ç«¯)", "èº«å¹… (å·¦ç«¯)", "èº«å¹… (å³ç«¯)"]
        col_x, col_y = st.columns(2)

        for i, label in enumerate(labels):
            with col_x if i % 2 == 0 else col_y:
                st.subheader(f"{label}ã®åº§æ¨™")
                x_val = st.number_input(
                    f"{label} Xåº§æ¨™ (0-{TARGET_WIDTH})",
                    min_value=0,
                    max_value=TARGET_WIDTH,
                    value=st.session_state.measure_coords[i][0] if st.session_state.measure_coords[i] else 0,
                    key=f'measure_x_{i}'
                )
                y_val = st.number_input(
                    f"{label} Yåº§æ¨™ (0-{TARGET_HEIGHT})",
                    min_value=0,
                    max_value=TARGET_HEIGHT,
                    value=st.session_state.measure_coords[i][1] if st.session_state.measure_coords[i] else 0,
                    key=f'measure_y_{i}'
                )
                st.session_state.measure_coords[i] = (x_val, y_val)
        
        # æˆ»ã‚‹ãƒœã‚¿ãƒ³
        if st.button("â† ã‚¹ãƒ†ãƒƒãƒ—1ã«æˆ»ã‚‹", key="back_to_step1"):
            st.session_state.step = 1
            st.experimental_rerun()

        if st.button("æ¡å¯¸çµæœã‚’è¡¨ç¤º", key="show_results"):
            st.session_state.step = 3
            st.experimental_rerun() # ã‚¹ãƒ†ãƒƒãƒ—3ã¸ç§»è¡Œ

    # --- ã‚¹ãƒ†ãƒƒãƒ— 3: çµæœã®è¡¨ç¤º ---
    elif st.session_state.step == 3:
        st.header("ã‚¹ãƒ†ãƒƒãƒ— 3: æ¡å¯¸çµæœ")
        
        # æ¸¬å®šãƒã‚¤ãƒ³ãƒˆã‚’Numpyé…åˆ—ã«å¤‰æ›
        measure_points = np.array(st.session_state.measure_coords, dtype="float32")
        
        try:
            height_cm, width_cm, pixels_per_cm_x, pixels_per_cm_y = measure_clothing(
                measure_points, TARGET_WIDTH, TARGET_HEIGHT, PAPER_WIDTH_CM, PAPER_HEIGHT_CM
            )

            st.success("æ¡å¯¸ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            
            st.subheader("ğŸ“ è¨ˆæ¸¬çµæœ")
            st.markdown(f"**ç€ä¸ˆ (æ¨å®š):** **{height_cm:.1f} cm**")
            st.markdown(f"**èº«å¹… (æ¨å®š):** **{width_cm:.1f} cm**")
            
            st.info("çµæœã¯ã€ã‚«ã‚¹ã‚¿ãƒ åŸºæº–ï¼ˆç¸¦51cmã€æ¨ª38cmï¼‰ã¨ã€æ‰‹å‹•ã§æŒ‡å®šã—ãŸ4ç‚¹ã«åŸºã¥ã„ã¦è¨ˆç®—ã•ã‚Œã¦ã„ã¾ã™ã€‚")
            
            # --- çµæœã®è¦–è¦šåŒ–ï¼ˆãƒ‡ãƒãƒƒã‚°æƒ…å ±ã¨ã—ã¦ï¼‰ ---
            warped_image_display = st.session_state.processed_image.copy()
            
            # è¨ˆæ¸¬ç‚¹ã‚’æç”»: [ç€ä¸ˆä¸Š(é’), ç€ä¸ˆä¸‹(é’), èº«å¹…å·¦(ç·‘), èº«å¹…å³(ç·‘)]
            colors = [(255, 0, 0), (255, 0, 0), (0, 255, 0), (0, 255, 0)] # é’, é’, ç·‘, ç·‘
            labels_draw = ["ç€ä¸ˆä¸Š", "ç€ä¸ˆä¸‹", "èº«å¹…å·¦", "èº«å¹…å³"]

            for i, (x, y) in enumerate(st.session_state.measure_coords):
                x_int, y_int = int(x), int(y)
                cv2.circle(warped_image_display, (x_int, y_int), 10, colors[i], -1)
                cv2.putText(warped_image_display, labels_draw[i], (x_int + 15, y_int), cv2.FONT_HERSHEY_SIMPLEX, 0.7, colors[i], 2)

            # ç€ä¸ˆã®ç·š
            cv2.line(warped_image_display, 
                     (int(st.session_state.measure_coords[0][0]), int(st.session_state.measure_coords[0][1])), 
                     (int(st.session_state.measure_coords[1][0]), int(st.session_state.measure_coords[1][1])), 
                     (255, 0, 0), 3) # é’ç·š
            
            # èº«å¹…ã®ç·š
            cv2.line(warped_image_display, 
                     (int(st.session_state.measure_coords[2][0]), int(st.session_state.measure_coords[2][1])), 
                     (int(st.session_state.measure_coords[3][0]), int(st.session_state.measure_coords[3][1])), 
                     (0, 255, 0), 3) # ç·‘ç·š


            st.subheader("ğŸ› è¨ˆæ¸¬ç‚¹ã¨çµæœã®ç¢ºèª")
            st.image(warped_image_display, channels="BGR", caption="è¨ˆæ¸¬ç‚¹ã‚’æç”»ã—ãŸè£œæ­£å¾Œã®ç”»åƒ", use_column_width=True)
            
            st.markdown(f"**è©³ç´°ã‚¹ã‚±ãƒ¼ãƒ«æƒ…å ±:**")
            st.markdown(f"ãƒ»æ¨ªæ–¹å‘ (1cmã‚ãŸã‚Š): {pixels_per_cm_x:.2f} pixels")
            st.markdown(f"ãƒ»ç¸¦æ–¹å‘ (1cmã‚ãŸã‚Š): {pixels_per_cm_y:.2f} pixels")


        except Exception as e:
            st.error(f"è¨ˆæ¸¬ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.exception(e)
            
        # æˆ»ã‚‹ãƒœã‚¿ãƒ³
        if st.button("â† ã‚¹ãƒ†ãƒƒãƒ—2ã«æˆ»ã‚‹", key="back_to_step2"):
            st.session_state.step = 2
            st.experimental_rerun()

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ
if __name__ == '__main__':
    main()
